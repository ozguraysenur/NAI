Daniel’s parents love the beach. Daniel and his sister and brother love the beach. The family’s dog 
loves the beach very much. But it is a problem to go to the beach every week. Daniel’s father gets tired from driving so many hours.
The rest of the family gets tired from sitting in the car for so many hours. Daniel’s mother says: 
It’s fun in the beach, but it takes too much time to get there and back!” Daniel and his sister and brother are very sad. 
They want to go to the beach, but it is a problem.
They try to go the swimming pool, but it is not the same thing. One day Daniel’s parents come to talk with the kids. They say: 
We have a problem to go to the beach every week, but we love the beach, and you love the beach, and the dog loves the beach. 
So we have a solution.
Contests[edit]
Between 2009 and 2012, recurrent neural networks and deep feedforward neural networks developed in Schmidhuber's research group won eight international competitions in pattern recognition and machine learning.[30][31] For example, the bi-directional and multi-dimensional long short-term memory (LSTM)[32][33][34][35] of Graves et al. won three competitions in connected handwriting recognition at the 2009 International Conference on Document Analysis and Recognition (ICDAR), without any prior knowledge about the three languages to be learned.[34][33]
Ciresan and colleagues won pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition,[36] the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge[37] and others. Their neural networks were the first pattern recognizers to achieve human-competitive or even superhuman performance[38] on benchmarks such as traffic sign recognition (IJCNN 2012), or the MNIST handwritten digits problem.
Researchers demonstrated (2010) that deep neural networks interfaced to a hidden Markov model with context-dependent states that define the neural network output layer can drastically reduce errors in large-vocabulary speech recognition tasks such as voice search.
GPU-based implementations[39] of this approach won many pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition,[36] the ISBI 2012 Segmentation of neuronal structures in EM stacks challenge,[40] the ImageNet Competition[41] and others.
Deep, highly nonlinear neural architectures similar to the neocognitron[42] and the "standard architecture of vision",[43] inspired by simple and complex cells, were pre-trained by unsupervised methods by Hinton.[44][24] A team from his lab won a 2012 contest sponsored by Merck to design software to help find molecules that might identify new drugs.[45]
Convolutional networks[edit]
As of 2011, the state of the art in deep learning feedforward networks alternated convolutional layers and max-pooling layers,[39][46] topped by several fully or sparsely connected layers followed by a final classification layer. Learning is usually done without unsupervised pre-training.
Such supervised deep learning methods were the first to achieve human-competitive performance on certain tasks.[38]
ANNs were able to guarantee shift invariance to deal with small and large natural objects in large cluttered scenes, only when invariance extended beyond shift, to all ANN-learned concepts, such as location, type (object class label), scale, lighting and others. This was realized in Developmental Networks (DNs)[47] whose embodiments are Where-What Networks, WWN-1 (2008)[48] through WWN-7 (2013).[49]
Models[edit]
This section may be confusing or unclear to readers. Please help us clarify the section. There might be a discussion about this on the talk page. (April 2017) (Learn how and when to remove this template message)
An (artificial) neural network is a network of simple elements called neurons, which receive input, change their internal state (activation) according to that input, and produce output depending on the input and activation. The network forms by connecting the output of certain neurons to the input of other neurons forming a directed, weighted graph. The weights as well as the functions that compute the activation can be modified by a process called learning which is governed by a learning rule.[50]
Components of an artificial neural network[edit]
Neurons[edit]
A neuron with label {\displaystyle j} j receiving an input {\displaystyle p_{j}(t)} {\displaystyle p_{j}(t)} from predecessor neurons consists of the following components:[50]
an activation {\displaystyle a_{j}(t)} {\displaystyle a_{j}(t)}, depending on a discrete time parameter,
possibly a threshold {\displaystyle \theta _{j}} \theta _{j}, which stays fixed unless changed by a learning function,
an activation function {\displaystyle f} f that computes the new activation at a given time {\displaystyle t+1} t+1 from {\displaystyle a_{j}(t)} {\displaystyle a_{j}(t)}, {\displaystyle \theta _{j}} \theta _{j} and the net input {\displaystyle p_{j}(t)} {\displaystyle p_{j}(t)} giving rise to the relation
{\displaystyle a_{j}(t+1)=f(a_{j}(t),p_{j}(t),\theta _{j})} {\displaystyle a_{j}(t+1)=f(a_{j}(t),p_{j}(t),\theta _{j})},
and an output function {\displaystyle f_{out}} {\displaystyle f_{out}} computing the output from the activation
{\displaystyle o_{j}(t)=f_{out}(a_{j}(t))} {\displaystyle o_{j}(t)=f_{out}(a_{j}(t))}.
Often the output function is simply the Identity function.
An input neuron has no predecessor but serves as input interface for the whole network. Similarly an output neuron has no successor and thus serves as output interface of the whole network.
Connections and weights[edit]
The network consists of connections, each connection transferring the output of a neuron {\displaystyle i} i to the input of a neuron {\displaystyle j} j. In this sense {\displaystyle i} i is the predecessor of {\displaystyle j} j and {\displaystyle j} j is the successor of {\displaystyle i} i. Each connection is assigned a weight {\displaystyle w_{ij}} w_{ij}.[50]
Propagation function[edit]
The propagation function computes the input {\displaystyle p_{j}(t)} {\displaystyle p_{j}(t)} to the neuron {\displaystyle j} j from the outputs {\displaystyle o_{i}(t)} {\displaystyle o_{i}(t)} of predecessor neurons and typically has the form[50]
{\displaystyle p_{j}(t)=\sum _{i}o_{i}(t)w_{ij}} {\displaystyle p_{j}(t)=\sum _{i}o_{i}(t)w_{ij}}.
Learning rule[edit]
The learning rule is a rule or an algorithm which modifies the parameters of the neural network, in order for a given input to the network to produce a favored output. This learning process typically amounts to modifying the weights and thresholds of the variables within the network.[50]
Neural networks as functions[edit]
See also: Graphical models
Neural network models can be viewed as simple mathematical models defining a function {\displaystyle \textstyle f:X\rightarrow Y} \textstyle f:X\rightarrow Y or a distribution over {\displaystyle \textstyle X} \textstyle X or both {\displaystyle \textstyle X} \textstyle X and {\displaystyle \textstyle Y} \textstyle Y. Sometimes models are intimately associated with a particular learning rule. A common use of the phrase "ANN model" is really the definition of a class of such functions (where members of the class are obtained by varying parameters, connection weights, or specifics of the architecture such as the number of neurons or their connectivity).
Mathematically, a neuron's network function {\displaystyle \textstyle f(x)} \textstyle f(x) is defined as a composition of other functions {\displaystyle \textstyle g_{i}(x)} \textstyle g_{i}(x), that can further be decomposed into other functions. This can be conveniently represented as a network structure, with arrows depicting the dependencies between functions. A widely used type of composition is the nonlinear weighted sum, where {\displaystyle \textstyle f(x)=K\left(\sum _{i}w_{i}g_{i}(x)\right)} \textstyle f(x)=K\left(\sum _{i}w_{i}g_{i}(x)\right), where {\displaystyle \textstyle K} \textstyle K (commonly referred to as the activation function[51]) is some predefined function, such as the hyperbolic tangent or sigmoid function or softmax function or rectifier function. The important characteristic of the activation function is that it provides a smooth transition as input values change, i.e. a small change in input produces a small change in output. The following refers to a collection of functions {\displaystyle \textstyle g_{i}} \textstyle g_{i} as a vector {\displaystyle \textstyle g=(g_{1},g_{2},\ldots ,g_{n})} \textstyle g=(g_{1},g_{2},\ldots ,g_{n}).
ANN dependency graph
This figure depicts such a decomposition of {\displaystyle \textstyle f} \textstyle f, with dependencies between variables indicated by arrows. These can be interpreted in two ways.
The first view is the functional view: the input {\displaystyle \textstyle x} \textstyle x is transformed into a 3-dimensional vector {\displaystyle \textstyle h} \textstyle h, which is then transformed into a 2-dimensional vector {\displaystyle \textstyle g} \textstyle g, which is finally transformed into {\displaystyle \textstyle f} \textstyle f. This view is most commonly encountered in the context of optimization.
The second view is the probabilistic view: the random variable {\displaystyle \textstyle F=f(G)} \textstyle F=f(G) depends upon the random variable {\displaystyle \textstyle G=g(H)} \textstyle G=g(H), which depends upon {\displaystyle \textstyle H=h(X)} \textstyle H=h(X), which depends upon the random variable {\displaystyle \textstyle X} \textstyle X. This view is most commonly encountered in the context of graphical models.
The two views are largely equivalent. In either case, for this particular architecture, the components of individual layers are independent of each other (e.g., the components of {\displaystyle \textstyle g} \textstyle g are independent of each other given their input {\displaystyle \textstyle h} \textstyle h). This naturally enables a degree of parallelism in the implementation.
Two separate depictions of the recurrent ANN dependency graph
Networks such as the previous one are commonly called feedforward, because their graph is a directed acyclic graph. Networks with cycles are commonly called recurrent. Such networks are commonly depicted in the manner shown at the top of the figure, where {\displaystyle \textstyle f} \textstyle f is shown as being dependent upon itself. However, an implied temporal dependence is not shown.
Learning